{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from typing import List, Dict, Union\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def generate_metadata_fundamental(df_metadata: pl.DataFrame, independent_var_name: str) -> dict:\n",
    "    sedol, *attribute_parts = independent_var_name.split(\"_\")\n",
    "    attribute_name = \"_\".join(attribute_parts)\n",
    "\n",
    "    # Filter the DataFrame once and select all needed columns\n",
    "    filtered_df = df_metadata.filter(pl.col(\"SEDOL\") == sedol).select(\n",
    "        [\"companyName\", \"tickerSymbol\", \"sector\", \"subsector\", \"ISOCode\"]\n",
    "    )\n",
    "\n",
    "    # Use .item() to get scalar values safely\n",
    "    company_name = filtered_df.select(\"companyName\").item()\n",
    "    company_ticker = filtered_df.select(\"tickerSymbol\").item()\n",
    "    sector = filtered_df.select(\"sector\").item()\n",
    "    subsector = filtered_df.select(\"subsector\").item()\n",
    "    country = filtered_df.select(\"ISOCode\").item()\n",
    "\n",
    "    return {\n",
    "        \"Variable Name\": independent_var_name,\n",
    "        \"Company Name\": company_name,\n",
    "        \"Company Ticker\": company_ticker,\n",
    "        \"sedol\": sedol,\n",
    "        \"sector\": sector,\n",
    "        \"subsector\": subsector,\n",
    "        \"country\": country,\n",
    "        \"Attribute\": attribute_name\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "def get_rolling_correlation(independent_var_name: str, series1: pl.Series, series2: pl.Series, window_size: int = 12) -> tuple[pl.DataFrame, pl.DataFrame]:\n",
    "    # Ensure series have a datetime index\n",
    "    if not isinstance(series1.index, pl.datatypes.Date) and not isinstance(series1.index, pl.datatypes.Datetime):\n",
    "        raise ValueError(\"series1 must have a datetime index\")\n",
    "    \n",
    "    # Create a DataFrame from the two series\n",
    "    df = pl.DataFrame({\n",
    "        \"series1\": series1,\n",
    "        \"series2\": series2,\n",
    "        \"date\": series1.index\n",
    "    })\n",
    "    \n",
    "    # Calculate rolling correlation\n",
    "    corr_series = df.select([\n",
    "        pl.col(\"date\"),\n",
    "        pl.corr(\"series1\", \"series2\").over(\"date\").rolling(window_size).alias(independent_var_name)\n",
    "    ])\n",
    "    \n",
    "    # Calculate statistics\n",
    "    stats = corr_series.select([\n",
    "        pl.lit(independent_var_name.split(\"_\")[0]).alias(\"SEDOL\"),\n",
    "        pl.lit(\"_\".join(independent_var_name.split(\"_\")[1:])).alias(\"Attribute\"),\n",
    "        pl.col(independent_var_name).quantile(0.25).alias(\"Quantile 25%\"),\n",
    "        pl.col(independent_var_name).mean().alias(\"Mean\"),\n",
    "        pl.col(independent_var_name).median().alias(\"Median\"),\n",
    "        pl.col(independent_var_name).quantile(0.75).alias(\"Quantile 75%\"),\n",
    "        pl.col(independent_var_name).last().alias(\"Latest Value\")\n",
    "    ])\n",
    "    \n",
    "    return corr_series, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation(df: pl.DataFrame, dependent_var_name: str, independent_var_name: str,\n",
    "                    rolling_corr: bool = True, rolling_windows: List[int] = [1,3,5,7]) -> Dict[str, Union[Dict, pl.DataFrame]]:\n",
    "    # Initialize result store\n",
    "    dict_result = {\n",
    "        \"Time Series\": {\"Yearly Rolling Corr\": {}},\n",
    "        \"Yearly Rolling Windows\": rolling_windows,\n",
    "        \"Stats\": {}\n",
    "    }\n",
    "    \n",
    "    for year in rolling_windows:\n",
    "        dict_result[\"Time Series\"][\"Yearly Rolling Corr\"][year] = {}\n",
    "        dict_result[\"Stats\"][f\"{year} Rolling Corr\"] = {}\n",
    "    \n",
    "    # Extract relevant columns and remove missing history between IV and DV\n",
    "    df_corr = df.select([dependent_var_name, independent_var_name])\n",
    "    df_corr = df_corr.filter(\n",
    "        ~pl.any_horizontal(pl.all().is_infinite()) & \n",
    "        ~pl.any_horizontal(pl.all().is_null())\n",
    "    )\n",
    "\n",
    "    dict_result[\"Stats\"][\"Num Obs\"] = df_corr.height\n",
    "\n",
    "    if df_corr.height <= 5:\n",
    "        if rolling_corr:\n",
    "            for year in rolling_windows:\n",
    "                dict_result[\"Time Series\"][f\"{year} Rolling Corr\"] = pl.DataFrame()\n",
    "                dict_result[\"Stats\"][f\"{year} Rolling Corr\"] = pl.DataFrame()\n",
    "        return dict_result\n",
    "\n",
    "    if rolling_corr:\n",
    "        for year in rolling_windows:\n",
    "            window_size = year * 52  # assume weekly data\n",
    "            df_rolling_corr, df_stats = get_rolling_correlation(\n",
    "                independent_var_name, \n",
    "                df_corr.get_column(dependent_var_name), \n",
    "                df_corr.get_column(independent_var_name), \n",
    "                window_size=window_size\n",
    "            )\n",
    "            dict_result[\"Time Series\"][f\"{year} Rolling Corr\"] = df_rolling_corr\n",
    "            dict_result[\"Stats\"][f\"{year} Rolling Corr\"] = df_stats\n",
    "\n",
    "    return dict_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rolling_corr_calc(df_universe: pl.DataFrame, df_dependent: pl.DataFrame, dependent_variable_name: str,\n",
    "                          run_rolling_corr: bool = True, rolling_windows: list[int] = [1,3,5,7]) -> list[pl.DataFrame]:\n",
    "    \n",
    "    chunk_size = 2500\n",
    "    num_chunks = (df_universe.width + chunk_size - 1) // chunk_size\n",
    "\n",
    "    df_timeseries_dict = {str(year): [] for year in rolling_windows}\n",
    "    df_stats_dict = {str(year): [] for year in rolling_windows}\n",
    "\n",
    "    def process_chunk(chunk_idx):\n",
    "        start_ind = chunk_idx * chunk_size\n",
    "        end_ind = min((chunk_idx + 1) * chunk_size, df_universe.width)\n",
    "        \n",
    "        df_independent = df_universe.select(pl.col(df_universe.columns[start_ind:end_ind]))\n",
    "        independent_variable_names = df_independent.columns\n",
    "        \n",
    "        df_temp = pl.concat([df_dependent, df_independent], how=\"horizontal\")\n",
    "\n",
    "        results = []\n",
    "        for independent_variable_name in independent_variable_names:\n",
    "            result = get_correlation(df_temp, dependent_variable_name, independent_variable_name, run_rolling_corr, rolling_windows)\n",
    "            results.append(result)\n",
    "        \n",
    "        return results\n",
    "\n",
    "    # Use ThreadPoolExecutor for parallelism\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        future_to_chunk = {executor.submit(process_chunk, i): i for i in range(num_chunks)}\n",
    "        for future in as_completed(future_to_chunk):\n",
    "            results = future.result()\n",
    "            for year in rolling_windows:\n",
    "                year_str = str(year)\n",
    "                timeseries_data = [item[\"Time Series\"][f\"{year} Rolling Corr\"] for item in results]\n",
    "                df_timeseries_dict[year_str].append(pl.concat(timeseries_data, how=\"horizontal\"))\n",
    "                \n",
    "                stats_data = [item[\"Stats\"][f\"{year} Rolling Corr\"] for item in results]\n",
    "                df_stats_dict[year_str].append(pl.concat(stats_data, how=\"vertical\"))\n",
    "\n",
    "    final_results = []\n",
    "    for year in rolling_windows:\n",
    "        year_str = str(year)\n",
    "        \n",
    "        df_timeseries = pl.concat(df_timeseries_dict[year_str], how=\"horizontal\")\n",
    "        df_timeseries = df_timeseries.filter(~pl.all(pl.all().is_infinite() | pl.all().is_null()))\n",
    "        df_timeseries = df_timeseries.with_row_count(\"Variable Name\")\n",
    "        \n",
    "        df_stats = pl.concat(df_stats_dict[year_str], how=\"vertical\")\n",
    "        df_stats = df_stats.filter(~pl.all(pl.all().is_infinite() | pl.all().is_null()))\n",
    "        df_stats = df_stats.with_row_count(\"Variable Name\")\n",
    "        \n",
    "        final_results.extend([df_timeseries, df_stats])\n",
    "\n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efficient Data Processing:\n",
    "Polars is designed for high-performance data processing. It uses Arrow memory format and leverages CPU cache more effectively, resulting in faster operations, particularly for large datasets.\n",
    "Vectorized Operations:\n",
    "Polars uses vectorized operations extensively, which are generally faster than the equivalent operations in Pandas, especially for complex calculations like rolling correlations.\n",
    "Parallelism:\n",
    "In the run_rolling_corr_calc function, we introduced parallelism using ThreadPoolExecutor. This allows the processing of different chunks of data concurrently, potentially leading to significant speedups on multi-core systems.\n",
    "Lazy Evaluation:\n",
    "Although not explicitly used in these conversions, Polars supports lazy evaluation, which can be leveraged for even more performance gains in complex data pipelines.\n",
    "Efficient Memory Usage:\n",
    "Polars is generally more memory-efficient than Pandas, which can lead to better performance, especially when working with large datasets that push the limits of available RAM.\n",
    "Optimized Filtering and Selection:\n",
    "Operations like filtering rows and selecting columns are highly optimized in Polars, which we've utilized in our conversions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
